{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-30T08:50:27.104920977Z",
     "start_time": "2023-07-30T08:50:26.384090929Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "    dataset_name = 'albertvillanova/universal_dependencies'\n",
    "    dataset_split = 'en_gum'\n",
    "    dataset = load_dataset(dataset_name, dataset_split, split='validation')\n",
    "    dataset = dataset.select_columns(['idx', 'text', 'tokens', 'head', 'deprel'])\n",
    "    # change head values from str to int\n",
    "    dataset = dataset.map(lambda example: {'head': [int(i) if i!='None' else None for i in example['head']]})\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset universal_dependencies (/home/vpnuser/.cache/huggingface/datasets/albertvillanova___universal_dependencies/en_gum/2.7.0/8a57de369f26d5e700a9f4db1f6b80387cd41918ee1dc23fb8190285a5199843)\n",
      "Loading cached processed dataset at /home/vpnuser/.cache/huggingface/datasets/albertvillanova___universal_dependencies/en_gum/2.7.0/8a57de369f26d5e700a9f4db1f6b80387cd41918ee1dc23fb8190285a5199843/cache-8a5e915bf309e1a3.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-30T08:51:34.334215470Z",
     "start_time": "2023-07-30T08:51:30.741468757Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "{'idx': 'GUM_academic_exposure-2',\n 'text': 'Research on adult-learned second language (L2) has provided considerable insight into the neurocognitive mechanisms underlying the learning and processing of L2 grammar [1] – [11].',\n 'tokens': ['Research',\n  'on',\n  'adult-learned',\n  'second',\n  'language',\n  '(',\n  'L2',\n  ')',\n  'has',\n  'provided',\n  'considerable',\n  'insight',\n  'into',\n  'the',\n  'neurocognitive',\n  'mechanisms',\n  'underlying',\n  'the',\n  'learning',\n  'and',\n  'processing',\n  'of',\n  'L2',\n  'grammar',\n  '[',\n  '1',\n  ']',\n  '–',\n  '[',\n  '11',\n  ']',\n  '.'],\n 'head': [10,\n  5,\n  5,\n  5,\n  1,\n  7,\n  5,\n  7,\n  10,\n  0,\n  12,\n  10,\n  16,\n  16,\n  16,\n  12,\n  16,\n  19,\n  17,\n  21,\n  19,\n  24,\n  24,\n  19,\n  26,\n  10,\n  26,\n  30,\n  30,\n  26,\n  30,\n  10],\n 'deprel': ['nsubj',\n  'case',\n  'amod',\n  'amod',\n  'nmod',\n  'punct',\n  'appos',\n  'punct',\n  'aux',\n  'root',\n  'amod',\n  'obj',\n  'case',\n  'det',\n  'amod',\n  'nmod',\n  'acl',\n  'det',\n  'obj',\n  'cc',\n  'conj',\n  'case',\n  'compound',\n  'nmod',\n  'punct',\n  'dep',\n  'punct',\n  'case',\n  'punct',\n  'nmod',\n  'punct',\n  'punct']}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-30T08:50:50.400403414Z",
     "start_time": "2023-07-30T08:50:50.396537182Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def clean_dataset(dataset):\n",
    "    def is_valid_sample(sample) -> bool:\n",
    "        # filter non english sentences\n",
    "        non_latin_letters = r'(?=[^a-zA-Z0-9])\\w'\n",
    "        if re.findall(non_latin_letters, sample['text']) != []:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def clean_text(sample):\n",
    "        # # remove paper's references (e.g. [15] [16] [17])\n",
    "        # cleaned_text = sample['text']\n",
    "        # pattern = r'(\\[\\d+\\]\\s?\\W\\s?)+'\n",
    "        # cleaned_text = re.sub(pattern, ' ', cleaned_text)\n",
    "        # # remove punctuation\n",
    "        # cleaned_text = re.sub(r'[^\\w\\s]', ' ', cleaned_text)\n",
    "        # # space collapse\n",
    "        # cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "        # sample['text'] = cleaned_text.strip()\n",
    "        return sample\n",
    "\n",
    "    dataset = dataset.filter(lambda example: is_valid_sample(example))\n",
    "    dataset = dataset.map(clean_text)\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T12:27:55.718832024Z",
     "start_time": "2023-07-26T12:27:55.714415534Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset universal_dependencies (/home/vpnuser/.cache/huggingface/datasets/albertvillanova___universal_dependencies/en_gum/2.7.0/8a57de369f26d5e700a9f4db1f6b80387cd41918ee1dc23fb8190285a5199843)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/784 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1fcdfaa0bec45fb8406a3fb9f66279a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Filter:   0%|          | 0/784 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d6c342cef4bd430eac40d74451f55c82"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/777 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db5ae64d9a494877a1666644c7d59aed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = get_dataset()\n",
    "dataset = clean_dataset(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T12:42:47.244001696Z",
     "start_time": "2023-07-26T12:42:43.170019627Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "777"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T12:42:49.479704628Z",
     "start_time": "2023-07-26T12:42:49.476461018Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "tmp_dataset = dataset.select_columns(['tokens', 'head', 'deprel'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-30T08:51:39.602251273Z",
     "start_time": "2023-07-30T08:51:39.598693971Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{24, 26, 5, 30}\n"
     ]
    }
   ],
   "source": [
    "tmp_df = pd.DataFrame(tmp_dataset[1])\n",
    "tmp_df_punct = tmp_df[tmp_df.deprel=='punct']\n",
    "tmp_df_not_punct = tmp_df[tmp_df.deprel!='punct']\n",
    "print(set(tmp_df_punct.index).intersection(set(tmp_df_not_punct['head'])))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-30T08:51:46.949080484Z",
     "start_time": "2023-07-30T08:51:46.944433981Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "            tokens  head    deprel\n0               Of     2      case\n1         interest     6       obl\n2             here     6    advmod\n3                ,     3     punct\n4          studies     6     nsubj\n5          suggest     0      root\n6             that    20      mark\n7                ,     7     punct\n8          despite    11      case\n9              the    11       det\n10    difficulties    20       obl\n11              in    13      mark\n12       acquiring    11       acl\n13              L2    15  compound\n14         grammar    13       obj\n15               ,    11     punct\n16           adult    18      amod\n17        learners    20     nsubj\n18             can    20       aux\n19     approximate     6     ccomp\n20     native-like    22      amod\n21          levels    20       obj\n22              of    24      case\n23             use    22      nmod\n24             and    27        cc\n25  neurocognitive    27      amod\n26      processing    24      conj\n27               [    29     punct\n28              12     6       dep\n29               ]    29     punct\n30               –    33      case\n31               [    33     punct\n32              15    29      nmod\n33               ]    33     punct\n34               .     6     punct",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens</th>\n      <th>head</th>\n      <th>deprel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Of</td>\n      <td>2</td>\n      <td>case</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>interest</td>\n      <td>6</td>\n      <td>obl</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>here</td>\n      <td>6</td>\n      <td>advmod</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>,</td>\n      <td>3</td>\n      <td>punct</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>studies</td>\n      <td>6</td>\n      <td>nsubj</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>suggest</td>\n      <td>0</td>\n      <td>root</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>that</td>\n      <td>20</td>\n      <td>mark</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>,</td>\n      <td>7</td>\n      <td>punct</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>despite</td>\n      <td>11</td>\n      <td>case</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>the</td>\n      <td>11</td>\n      <td>det</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>difficulties</td>\n      <td>20</td>\n      <td>obl</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>in</td>\n      <td>13</td>\n      <td>mark</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>acquiring</td>\n      <td>11</td>\n      <td>acl</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>L2</td>\n      <td>15</td>\n      <td>compound</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>grammar</td>\n      <td>13</td>\n      <td>obj</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>,</td>\n      <td>11</td>\n      <td>punct</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>adult</td>\n      <td>18</td>\n      <td>amod</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>learners</td>\n      <td>20</td>\n      <td>nsubj</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>can</td>\n      <td>20</td>\n      <td>aux</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>approximate</td>\n      <td>6</td>\n      <td>ccomp</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>native-like</td>\n      <td>22</td>\n      <td>amod</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>levels</td>\n      <td>20</td>\n      <td>obj</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>of</td>\n      <td>24</td>\n      <td>case</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>use</td>\n      <td>22</td>\n      <td>nmod</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>and</td>\n      <td>27</td>\n      <td>cc</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>neurocognitive</td>\n      <td>27</td>\n      <td>amod</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>processing</td>\n      <td>24</td>\n      <td>conj</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>[</td>\n      <td>29</td>\n      <td>punct</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>12</td>\n      <td>6</td>\n      <td>dep</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>]</td>\n      <td>29</td>\n      <td>punct</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>–</td>\n      <td>33</td>\n      <td>case</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>[</td>\n      <td>33</td>\n      <td>punct</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>15</td>\n      <td>29</td>\n      <td>nmod</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>]</td>\n      <td>33</td>\n      <td>punct</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>.</td>\n      <td>6</td>\n      <td>punct</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tmp_dataset[2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-30T08:54:38.381031595Z",
     "start_time": "2023-07-30T08:54:38.376591046Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "{'idx': 'GUM_academic_exposure-2',\n 'text': 'Research on adult-learned second language (L2) has provided considerable insight into the neurocognitive mechanisms underlying the learning and processing of L2 grammar [1] – [11].',\n 'tokens': ['Research',\n  'on',\n  'adult-learned',\n  'second',\n  'language',\n  '(',\n  'L2',\n  ')',\n  'has',\n  'provided',\n  'considerable',\n  'insight',\n  'into',\n  'the',\n  'neurocognitive',\n  'mechanisms',\n  'underlying',\n  'the',\n  'learning',\n  'and',\n  'processing',\n  'of',\n  'L2',\n  'grammar',\n  '[',\n  '1',\n  ']',\n  '–',\n  '[',\n  '11',\n  ']',\n  '.'],\n 'head': [10,\n  5,\n  5,\n  5,\n  1,\n  7,\n  5,\n  7,\n  10,\n  0,\n  12,\n  10,\n  16,\n  16,\n  16,\n  12,\n  16,\n  19,\n  17,\n  21,\n  19,\n  24,\n  24,\n  19,\n  26,\n  10,\n  26,\n  30,\n  30,\n  26,\n  30,\n  10],\n 'deprel': ['nsubj',\n  'case',\n  'amod',\n  'amod',\n  'nmod',\n  'punct',\n  'appos',\n  'punct',\n  'aux',\n  'root',\n  'amod',\n  'obj',\n  'case',\n  'det',\n  'amod',\n  'nmod',\n  'acl',\n  'det',\n  'obj',\n  'cc',\n  'conj',\n  'case',\n  'compound',\n  'nmod',\n  'punct',\n  'dep',\n  'punct',\n  'case',\n  'punct',\n  'nmod',\n  'punct',\n  'punct']}"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T12:43:02.727390177Z",
     "start_time": "2023-07-26T12:43:02.723501198Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'set'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.map_locations\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: unhashable type: 'set'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pandas._libs.index.IndexEngine._call_map_locations'\n",
      "Traceback (most recent call last):\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5231, in pandas._libs.hashtable.PyObjectHashTable.map_locations\n",
      "TypeError: unhashable type: 'set'\n"
     ]
    },
    {
     "data": {
      "text/plain": "{}        760\n{/}         6\n{$}         3\n{@}         2\n{+, ‘}      1\n{…}         1\n{`}         1\n{&}         1\n{|}         1\n{=}         1\nName: special_chars_wo_punctuations, dtype: int64"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dict(text=dataset['text']))\n",
    "df['chars_set'] = df['text'].apply(lambda x: set(x))\n",
    "df['special_chars'] = df['chars_set'].apply(lambda x: x - set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\\' '))\n",
    "df['special_chars_wo_punctuations'] = df['special_chars'].apply(lambda x: x - set('!\"(),-.:;[]–“”—?’'))\n",
    "df['special_chars_wo_punctuations'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T14:19:38.677431042Z",
     "start_time": "2023-07-26T14:19:38.641532166Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "True     613\nFalse    164\nName: is_valid, dtype: int64"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_valid_sample(sample) -> bool:\n",
    "    letters = set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\\' ')\n",
    "    numbers = set() #set('0123456789')\n",
    "    punctuations = set('!\"(),-.:;[]–“”—?’')\n",
    "    if set(sample['text']) - (letters | numbers | punctuations) != set():\n",
    "        return False\n",
    "    return True\n",
    "# df['text_wo_ref'] = df['text'].apply(lambda x: re.sub(r'(\\[\\d+\\]\\s?\\W\\s?)+', ' ', x))\n",
    "df['is_valid'] = df.apply(is_valid_sample, axis=1)\n",
    "df['is_valid'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T14:29:11.928085304Z",
     "start_time": "2023-07-26T14:29:11.885611480Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                     0\n0                                         Introduction\n1    Research on adult-learned second language (L2)...\n2    Of interest here, studies suggest that, despit...\n3    However, it is not enough to have attained suc...\n4    Crucially, it is also desirable to retain them...\n..                                                 ...\n772          Do not drink if underage in your country.\n773                                 Things You'll Need\n774  Each handle of vodka (1.75 liters, about a hal...\n775  Coffee filter, cheesecloth / muslin, or an ext...\n776            Large funnel or strainer to hold filter\n\n[777 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Introduction</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Research on adult-learned second language (L2)...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Of interest here, studies suggest that, despit...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>However, it is not enough to have attained suc...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Crucially, it is also desirable to retain them...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>772</th>\n      <td>Do not drink if underage in your country.</td>\n    </tr>\n    <tr>\n      <th>773</th>\n      <td>Things You'll Need</td>\n    </tr>\n    <tr>\n      <th>774</th>\n      <td>Each handle of vodka (1.75 liters, about a hal...</td>\n    </tr>\n    <tr>\n      <th>775</th>\n      <td>Coffee filter, cheesecloth / muslin, or an ext...</td>\n    </tr>\n    <tr>\n      <th>776</th>\n      <td>Large funnel or strainer to hold filter</td>\n    </tr>\n  </tbody>\n</table>\n<p>777 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T14:14:07.670420272Z",
     "start_time": "2023-07-26T14:14:07.664751707Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def clean_dataset(dataset):\n",
    "    def is_valid_sample(sample) -> bool:\n",
    "        # filter non english sentences\n",
    "        letters = set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\\' ')\n",
    "        # numbers = set('0123456789')\n",
    "        punctuations = set('!\"(),-.:;[]–“”—?’')\n",
    "        if set(sample['text']) - (letters | punctuations) != set():\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def clean_tokens(sample):\n",
    "        # remove paper's references (e.g. [15] [16] [17])\n",
    "        cleaned_text = sample['text']\n",
    "        pattern = r'(\\[\\d+\\]\\s?\\W\\s?)+'\n",
    "        cleaned_text = re.sub(pattern, ' ', cleaned_text)\n",
    "        # remove punctuation\n",
    "        cleaned_text = re.sub(r'[^\\w\\s]', ' ', cleaned_text)\n",
    "        # space collapse\n",
    "        cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "        sample['text'] = cleaned_text.strip()\n",
    "        return sample\n",
    "\n",
    "    dataset = dataset.filter(lambda example: is_valid_sample(example))\n",
    "    # dataset = dataset.map(clean_tokens)\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T11:25:39.437521726Z",
     "start_time": "2023-07-27T11:25:39.433837169Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "Filter:   0%|          | 0/777 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e2e34151de3d43cbb364f8728ddac4e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = clean_dataset(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T11:25:46.639882280Z",
     "start_time": "2023-07-27T11:25:46.463785213Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['idx', 'text', 'tokens', 'head', 'deprel'],\n    num_rows: 613\n})"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T11:25:48.414932209Z",
     "start_time": "2023-07-27T11:25:48.408250823Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "{'idx': 'GUM_academic_exposure-4',\n 'text': 'However, it is not enough to have attained such native-like levels.',\n 'tokens': ['However',\n  ',',\n  'it',\n  'is',\n  'not',\n  'enough',\n  'to',\n  'have',\n  'attained',\n  'such',\n  'native-like',\n  'levels',\n  '.'],\n 'head': [6, 1, 6, 6, 6, 0, 9, 9, 6, 12, 12, 9, 6],\n 'deprel': ['advmod',\n  'punct',\n  'expl',\n  'cop',\n  'advmod',\n  'root',\n  'mark',\n  'aux',\n  'csubj',\n  'amod',\n  'amod',\n  'obj',\n  'punct']}"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T11:25:58.188247181Z",
     "start_time": "2023-07-27T11:25:58.141989779Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "tmp_dataset = dataset.select_columns(['tokens', 'head', 'deprel'])\n",
    "tokens_df = list()\n",
    "for tmp_sample in tmp_dataset:\n",
    "    tokens_df.append(pd.DataFrame(tmp_sample))\n",
    "tokens_df = pd.concat(tokens_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T11:29:01.207507697Z",
     "start_time": "2023-07-27T11:29:00.970636158Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "          tokens  head  deprel\n0   Introduction     0    root\n0        However     6  advmod\n2             it     6    expl\n3             is     6     cop\n4            not     6  advmod\n..           ...   ...     ...\n2             or     4      cc\n3       strainer     2    conj\n4             to     6    mark\n5           hold     2     acl\n6         filter     6     obj\n\n[9703 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens</th>\n      <th>head</th>\n      <th>deprel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Introduction</td>\n      <td>0</td>\n      <td>root</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>However</td>\n      <td>6</td>\n      <td>advmod</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>it</td>\n      <td>6</td>\n      <td>expl</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>is</td>\n      <td>6</td>\n      <td>cop</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>not</td>\n      <td>6</td>\n      <td>advmod</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>or</td>\n      <td>4</td>\n      <td>cc</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>strainer</td>\n      <td>2</td>\n      <td>conj</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>to</td>\n      <td>6</td>\n      <td>mark</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>hold</td>\n      <td>2</td>\n      <td>acl</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>filter</td>\n      <td>6</td>\n      <td>obj</td>\n    </tr>\n  </tbody>\n</table>\n<p>9703 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_df[tokens_df.deprel!='punct']."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T11:31:04.252206153Z",
     "start_time": "2023-07-27T11:31:04.206847467Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "         tokens  head deprel\n0  Introduction     0   root",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens</th>\n      <th>head</th>\n      <th>deprel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Introduction</td>\n      <td>0</td>\n      <td>root</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tmp_sample)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T11:28:51.046358455Z",
     "start_time": "2023-07-27T11:28:51.032384606Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "True     10195\nFalse      768\nName: is_valid, dtype: int64"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_valid_token(sample) -> bool:\n",
    "    letters = set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\\' ')\n",
    "    punctuations = set('.’()')\n",
    "    if set(sample['tokens']) - (letters | punctuations) != set():\n",
    "        return False\n",
    "    return True\n",
    "# df['text_wo_ref'] = df['text'].apply(lambda x: re.sub(r'(\\[\\d+\\]\\s?\\W\\s?)+', ' ', x))\n",
    "tokens_df['is_valid'] = tokens_df.apply(is_valid_token, axis=1)\n",
    "tokens_df['is_valid'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T11:38:14.952964327Z",
     "start_time": "2023-07-27T11:38:14.843949797Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "                   tokens  head     deprel  is_valid\n10            native-like    12       amod     False\n28          self-directed    30       amod     False\n8                hands-on    10       amod     False\n15            short-lived    14      advcl     False\n2          self-appointed     4       amod     False\n10          Major-General     8        obj     False\n14       Command-in-Chief    11      appos     False\n30        half-understood    32       amod     False\n7             thirty-five     6       amod     False\n7            wrought-iron    10       amod     False\n4            eighth-grade     7   compound     False\n18           night-monkey    21  nmod:poss     False\n47         council-member    46        obj     False\n50           ill-mannered    52       amod     False\n9           well-received    11       amod     False\n50          tree-cuttings    49       nmod     False\n11          house-servant     8      appos     False\n4         leaf-collecting     6       amod     False\n22          fine-knuckled    24       amod     False\n21        Black-and-White    23       amod     False\n12           sea-sickness    11       conj     False\n18           half-smiling    15      advcl     False\n10                cut-off     0       root     False\n6              pro-active     0       root     False\n8   billion-year-contract     7        obj     False\n15           high-ranking    17       amod     False\n32                E-meter    31      xcomp     False\n38        well-understood    40       amod     False\n20    chlorine-containing    22       amod     False\n24      iodine-containing    26       amod     False\n11             re-emerged     7       conj     False\n20            job-seekers    20        obj     False\n20            post-modern    22       amod     False\n5            Nesf-e-Jahan     3      xcomp     False\n4            hand-painted     6       amod     False\n3              tree-lined     5       amod     False\n6             north-south    10       amod     False\n8               east-west     7       conj     False\n0                 Naqsh-e     2   compound     False\n10           seven-colour    13   compound     False\n2             forty-eight     4     nummod     False\n8      religious-national    10       amod     False\n1              one-liners    18        obl     False\n4            three-liners    18        obl     False\n7              one-minute     9       amod     False\n0            Joke-telling     3      nsubj     False\n6             twisty-ness     1        obl     False\n5             purse-space     4       nmod     False\n5              twist-tied     4       conj     False\n1              paper-type     4       amod     False\n0            Plastic-type     3       amod     False\n9        brightly-colored    11       amod     False\n17                t-shirt    14       conj     False\n3                 t-shirt     2        obj     False",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens</th>\n      <th>head</th>\n      <th>deprel</th>\n      <th>is_valid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>native-like</td>\n      <td>12</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>self-directed</td>\n      <td>30</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>hands-on</td>\n      <td>10</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>short-lived</td>\n      <td>14</td>\n      <td>advcl</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>self-appointed</td>\n      <td>4</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Major-General</td>\n      <td>8</td>\n      <td>obj</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Command-in-Chief</td>\n      <td>11</td>\n      <td>appos</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>half-understood</td>\n      <td>32</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>thirty-five</td>\n      <td>6</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>wrought-iron</td>\n      <td>10</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>eighth-grade</td>\n      <td>7</td>\n      <td>compound</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>night-monkey</td>\n      <td>21</td>\n      <td>nmod:poss</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>council-member</td>\n      <td>46</td>\n      <td>obj</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>ill-mannered</td>\n      <td>52</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>well-received</td>\n      <td>11</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>tree-cuttings</td>\n      <td>49</td>\n      <td>nmod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>house-servant</td>\n      <td>8</td>\n      <td>appos</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>leaf-collecting</td>\n      <td>6</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>fine-knuckled</td>\n      <td>24</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Black-and-White</td>\n      <td>23</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>sea-sickness</td>\n      <td>11</td>\n      <td>conj</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>half-smiling</td>\n      <td>15</td>\n      <td>advcl</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>cut-off</td>\n      <td>0</td>\n      <td>root</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>pro-active</td>\n      <td>0</td>\n      <td>root</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>billion-year-contract</td>\n      <td>7</td>\n      <td>obj</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>high-ranking</td>\n      <td>17</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>E-meter</td>\n      <td>31</td>\n      <td>xcomp</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>well-understood</td>\n      <td>40</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>chlorine-containing</td>\n      <td>22</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>iodine-containing</td>\n      <td>26</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>re-emerged</td>\n      <td>7</td>\n      <td>conj</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>job-seekers</td>\n      <td>20</td>\n      <td>obj</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>post-modern</td>\n      <td>22</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Nesf-e-Jahan</td>\n      <td>3</td>\n      <td>xcomp</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>hand-painted</td>\n      <td>6</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tree-lined</td>\n      <td>5</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>north-south</td>\n      <td>10</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>east-west</td>\n      <td>7</td>\n      <td>conj</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Naqsh-e</td>\n      <td>2</td>\n      <td>compound</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>seven-colour</td>\n      <td>13</td>\n      <td>compound</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>forty-eight</td>\n      <td>4</td>\n      <td>nummod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>religious-national</td>\n      <td>10</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>one-liners</td>\n      <td>18</td>\n      <td>obl</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>three-liners</td>\n      <td>18</td>\n      <td>obl</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>one-minute</td>\n      <td>9</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Joke-telling</td>\n      <td>3</td>\n      <td>nsubj</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>twisty-ness</td>\n      <td>1</td>\n      <td>obl</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>purse-space</td>\n      <td>4</td>\n      <td>nmod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>twist-tied</td>\n      <td>4</td>\n      <td>conj</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>paper-type</td>\n      <td>4</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Plastic-type</td>\n      <td>3</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>brightly-colored</td>\n      <td>11</td>\n      <td>amod</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>t-shirt</td>\n      <td>14</td>\n      <td>conj</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>t-shirt</td>\n      <td>2</td>\n      <td>obj</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_df[(tokens_df.is_valid==False) & (tokens_df.deprel!='punct')]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T11:38:16.567503558Z",
     "start_time": "2023-07-27T11:38:16.534344583Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "sample = dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T11:40:20.177568766Z",
     "start_time": "2023-07-27T11:40:20.164298103Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "{'idx': 'GUM_academic_exposure-1',\n 'text': 'Introduction',\n 'tokens': ['Introduction'],\n 'head': [0],\n 'deprel': ['root']}"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T11:40:22.142117058Z",
     "start_time": "2023-07-27T11:40:22.127005195Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [],
   "source": [
    "sample = dataset[3]\n",
    "sample_df = pd.DataFrame.from_dict(dict(tokens=sample['tokens'], head=sample['head'], deprel=sample['deprel']))\n",
    "orig_sample_df = sample_df.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T12:14:34.604562516Z",
     "start_time": "2023-07-27T12:14:34.591773971Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "punct_tokens = sample_df['deprel'] == 'punct'\n",
    "tokens_shift = punct_tokens.cumsum().astype(int)\n",
    "punct_indices = sample_df[punct_tokens].index\n",
    "\n",
    "sample_df.loc[sample_df['head'] >= len(sample_df), 'head'] = -1\n",
    "sample_df.loc[sample_df['head'].isin(punct_indices), ['head', 'deprel']] = -1, None\n",
    "indices_to_shift = (~punct_tokens)&(sample_df['head']>=0)\n",
    "sample_df.loc[indices_to_shift, 'head'] = sample_df[indices_to_shift].apply(lambda x: x['head']-tokens_shift[x['head']], axis=1)\n",
    "sample_df = sample_df.drop(punct_indices).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T12:14:35.208468381Z",
     "start_time": "2023-07-27T12:14:35.182972825Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "data": {
      "text/plain": "       tokens  head      deprel\n0     Overall    10      advmod\n1         the     3         det\n2     results    10  nsubj:pass\n3          of     7        case\n4         the     7         det\n5         six     7      nummod\n6     studies     3        nmod\n7        have    10         aux\n8        been    10    aux:pass\n9       taken     0        root\n10         to    12        mark\n11    suggest    10       xcomp\n12        the    -1        None\n13  following    12         obj",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens</th>\n      <th>head</th>\n      <th>deprel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Overall</td>\n      <td>10</td>\n      <td>advmod</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the</td>\n      <td>3</td>\n      <td>det</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>results</td>\n      <td>10</td>\n      <td>nsubj:pass</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>of</td>\n      <td>7</td>\n      <td>case</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>the</td>\n      <td>7</td>\n      <td>det</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>six</td>\n      <td>7</td>\n      <td>nummod</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>studies</td>\n      <td>3</td>\n      <td>nmod</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>have</td>\n      <td>10</td>\n      <td>aux</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>been</td>\n      <td>10</td>\n      <td>aux:pass</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>taken</td>\n      <td>0</td>\n      <td>root</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>to</td>\n      <td>12</td>\n      <td>mark</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>suggest</td>\n      <td>10</td>\n      <td>xcomp</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>the</td>\n      <td>-1</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>following</td>\n      <td>12</td>\n      <td>obj</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T12:14:35.857700033Z",
     "start_time": "2023-07-27T12:14:35.851159417Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "data": {
      "text/plain": "       tokens  head      deprel\n0     Overall    11      advmod\n1           ,     1       punct\n2         the     4         det\n3     results    11  nsubj:pass\n4          of     8        case\n5         the     8         det\n6         six     8      nummod\n7     studies     4        nmod\n8        have    11         aux\n9        been    11    aux:pass\n10      taken     0        root\n11         to    13        mark\n12    suggest    11       xcomp\n13        the    15         det\n14  following    13         obj\n15          .    11       punct",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens</th>\n      <th>head</th>\n      <th>deprel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Overall</td>\n      <td>11</td>\n      <td>advmod</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>,</td>\n      <td>1</td>\n      <td>punct</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>the</td>\n      <td>4</td>\n      <td>det</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>results</td>\n      <td>11</td>\n      <td>nsubj:pass</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>of</td>\n      <td>8</td>\n      <td>case</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>the</td>\n      <td>8</td>\n      <td>det</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>six</td>\n      <td>8</td>\n      <td>nummod</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>studies</td>\n      <td>4</td>\n      <td>nmod</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>have</td>\n      <td>11</td>\n      <td>aux</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>been</td>\n      <td>11</td>\n      <td>aux:pass</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>taken</td>\n      <td>0</td>\n      <td>root</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>to</td>\n      <td>13</td>\n      <td>mark</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>suggest</td>\n      <td>11</td>\n      <td>xcomp</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>the</td>\n      <td>15</td>\n      <td>det</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>following</td>\n      <td>13</td>\n      <td>obj</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>.</td>\n      <td>11</td>\n      <td>punct</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_sample_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T12:14:40.057172600Z",
     "start_time": "2023-07-27T12:14:40.052223841Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['idx', 'text', 'tokens', 'head', 'deprel'],\n    num_rows: 613\n})"
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T13:03:18.350190485Z",
     "start_time": "2023-07-27T13:03:18.309470826Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/613 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1734c601e37c4143aa3c6d6275544bb0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clean_for_tts(sample):\n",
    "    sample['text'] = sample['text'].replace('“', '\"').replace('”', '\"').replace('’', '\\'').replace('–', '-')\n",
    "    return sample\n",
    "\n",
    "dataset = dataset.map(clean_for_tts)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T13:08:14.152766293Z",
     "start_time": "2023-07-27T13:08:13.965486676Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [],
   "source": [
    "with open(\"data_for_tts.csv\", 'w') as f:\n",
    "    for sample in dataset:\n",
    "        f.write(sample['idx'] + '\\t' + sample['text']+'\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T13:09:00.907363177Z",
     "start_time": "2023-07-27T13:09:00.868020774Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['idx', 'text', 'tokens', 'head', 'deprel'],\n    num_rows: 784\n})"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-30T11:53:43.194942061Z",
     "start_time": "2023-07-30T11:53:43.187563703Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'tokens'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m dataset:\n\u001B[0;32m----> 2\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfixed\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m  \u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtokens\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[1;32m      3\u001B[0m         \u001B[38;5;28mprint\u001B[39m(i)\n",
      "File \u001B[0;32m~/venv/nlp/lib/python3.10/site-packages/datasets/arrow_dataset.py:2792\u001B[0m, in \u001B[0;36mDataset.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   2790\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):  \u001B[38;5;66;03m# noqa: F811\u001B[39;00m\n\u001B[1;32m   2791\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001B[39;00m\n\u001B[0;32m-> 2792\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/venv/nlp/lib/python3.10/site-packages/datasets/arrow_dataset.py:2776\u001B[0m, in \u001B[0;36mDataset._getitem\u001B[0;34m(self, key, **kwargs)\u001B[0m\n\u001B[1;32m   2774\u001B[0m format_kwargs \u001B[38;5;241m=\u001B[39m format_kwargs \u001B[38;5;28;01mif\u001B[39;00m format_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[1;32m   2775\u001B[0m formatter \u001B[38;5;241m=\u001B[39m get_formatter(format_type, features\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info\u001B[38;5;241m.\u001B[39mfeatures, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mformat_kwargs)\n\u001B[0;32m-> 2776\u001B[0m pa_subtable \u001B[38;5;241m=\u001B[39m \u001B[43mquery_table\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_indices\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_indices\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   2777\u001B[0m formatted_output \u001B[38;5;241m=\u001B[39m format_table(\n\u001B[1;32m   2778\u001B[0m     pa_subtable, key, formatter\u001B[38;5;241m=\u001B[39mformatter, format_columns\u001B[38;5;241m=\u001B[39mformat_columns, output_all_columns\u001B[38;5;241m=\u001B[39moutput_all_columns\n\u001B[1;32m   2779\u001B[0m )\n\u001B[1;32m   2780\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m formatted_output\n",
      "File \u001B[0;32m~/venv/nlp/lib/python3.10/site-packages/datasets/formatting/formatting.py:583\u001B[0m, in \u001B[0;36mquery_table\u001B[0;34m(table, key, indices)\u001B[0m\n\u001B[1;32m    581\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    582\u001B[0m     size \u001B[38;5;241m=\u001B[39m indices\u001B[38;5;241m.\u001B[39mnum_rows \u001B[38;5;28;01mif\u001B[39;00m indices \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m table\u001B[38;5;241m.\u001B[39mnum_rows\n\u001B[0;32m--> 583\u001B[0m     \u001B[43m_check_valid_index_key\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    584\u001B[0m \u001B[38;5;66;03m# Query the main table\u001B[39;00m\n\u001B[1;32m    585\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m indices \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/venv/nlp/lib/python3.10/site-packages/datasets/formatting/formatting.py:536\u001B[0m, in \u001B[0;36m_check_valid_index_key\u001B[0;34m(key, size)\u001B[0m\n\u001B[1;32m    534\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Iterable):\n\u001B[1;32m    535\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(key) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 536\u001B[0m         _check_valid_index_key(\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m, size\u001B[38;5;241m=\u001B[39msize)\n\u001B[1;32m    537\u001B[0m         _check_valid_index_key(\u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mmin\u001B[39m(key)), size\u001B[38;5;241m=\u001B[39msize)\n\u001B[1;32m    538\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mValueError\u001B[0m: invalid literal for int() with base 10: 'tokens'"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-30T11:54:04.857096999Z",
     "start_time": "2023-07-30T11:54:04.565395117Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
